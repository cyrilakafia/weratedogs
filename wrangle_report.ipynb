{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Wrangle and Analyze Data\n",
    "\n",
    "**Documentation for data wrangling steps: gather, assess, and clean**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering\n",
    "\n",
    "The data was gathered from three different sources and in three different formats as described below:\n",
    "\n",
    "1. The WeRateDogs Twitter archive. This file was provided by Udacity and was downloaded manually by clicking the following link: twitter_archive_enhanced.csv and was saved as a csv file.\n",
    "\n",
    "2. The tweet image predictions. This file was hosted on Udacity's servers and was downloaded programmatically using the Requests library and the following URL: image_predictions.tsv and was saved as a tsv file.\n",
    "\n",
    "3. Retweet and Favourite count for each tweet. This file was queried from Twitter's API using the Tweepy library and the tweet IDs in the `WeRateDogs` Twitter archive. The data was stored in a text file file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Assessing\n",
    "\n",
    "The data was assessed visually and programmatically for quality and tidiness issues.\n",
    "\n",
    "The programmatic assessment was done using the following pandas functions:\n",
    "\n",
    "1. `df.info()` to get a concise summary of the DataFrame.\n",
    "\n",
    "2. `df.describe()` to get a mathemmatical summary of the columns with numerical data in the DataFrame.\n",
    "\n",
    "3. `df.sample()` to get a random sample of the DataFrame.\n",
    "\n",
    "4. `df.value_counts()` to get a count of unique values in a column.\n",
    "\n",
    "5. `df.duplicated()` to get a count of duplicate rows in the DataFrame.\n",
    "\n",
    "6. `df.isnull().sum()` to get a count of null values in each column.\n",
    "\n",
    "7. `df[df.column_name].unique()` to get a list of unique values in a column.\n",
    "\n",
    "... and many more.\n",
    "\n",
    "The results of the assesments were documented and are shown below.\n",
    "\n",
    "### Quality issues\n",
    "\n",
    "`twitter_archive_enhance`\n",
    "\n",
    "1. HTML tags in source column need to be removed\n",
    "\n",
    "2. Null values in columns `in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp and expanded_urls` \n",
    "\n",
    "3. Null values written as 'None' in `name`, `floofer`, `doggo`, `pupper`, `puppo` columns.\n",
    "\n",
    "4. The `timestamp` datatype should be datetime not object\n",
    "\n",
    "5. There are retweets part of the dataset which should now be the case according to the instructions\n",
    "\n",
    "6. The `source` column has only 4 different unique values, thus, they should be categorical instead of objects\n",
    "\n",
    "7. Some names in the `names` column were wrongly written as 'a'\n",
    "\n",
    "8. Some numerator ratings are significantly smaller than their denominator counterparts. This is odd and does not follow the defined schema or theme of the ratings which, i.e., 11/10, 14/10 etc.\n",
    "\n",
    "9. 1 row has rating_denominator set to 0 which is not realistic.\n",
    "\n",
    "10. 2 rows have rating_numerator set to 0 which is not realistic.\n",
    "\n",
    "### Tidiness issues\n",
    "\n",
    "`twitter_archive_engance`\n",
    "\n",
    "1. The dog stages variable should form one column instead of four different columns\n",
    "\n",
    "2. The two ratings columns in `twitter_archive_en` should be one column\n",
    "\n",
    "`tweet_json`\n",
    "\n",
    "3. `tweet_json.txt` and `twitter_archive_enhance` can be combined to form a table with one observational unit, i.e., tweets and their related statistics and information (no predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "A copy of all three datasets were made befoe cleaning and the cleaning process was done in the following order:\n",
    "\n",
    "1. Define: Define the cleaning steps required to address the issue.\n",
    "\n",
    "2. Code: Write the code to address the issue.\n",
    "\n",
    "3. Test: Test the code to ensure the issue was addressed.\n",
    "\n",
    "\n",
    "Methods and Function used in cleaning the data include:\n",
    "\n",
    "1. `df.drop()` to drop columns and rows\n",
    "\n",
    "2. `.str.replace()` to replace values in a column\n",
    "\n",
    "3. `df.astype()` to change the datatype of a column\n",
    "\n",
    "4. `pd.merge()` to merge two DataFrames\n",
    "\n",
    "5. `pd.to_datetime()` to convert a column to datetime\n",
    "\n",
    "6. `.str.extract()` and regular expression to extract values from a column\n",
    "\n",
    "... and many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Storing\n",
    "\n",
    "The cleaned data were stored as csv files using the `to_csv()` method in pandas:\n",
    "\n",
    "1. `twitter_archive_master.csv`\n",
    "\n",
    "2. `twitter_archive_tweet_info.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. https://help.start.gg/en/articles/1987102-customizing-text-with-markdown#:~:text=Aligning%20Text,the%20text%20in%20div%20tags.\n",
    "\n",
    "2. https://www.w3schools.com/PYTHON/matplotlib_pie_charts.asp\n",
    "\n",
    "3. https://www.digitalocean.com/community/tutorials/pandas-merge-two-dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0c3bd7c9556569dc1ef9443ec91d3b9c536ca2b41c586f54944571d5f995c32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
